{
  "hash": "bbf966dcc5c9323e18b7e38385ed1cd0",
  "result": {
    "markdown": "---\ntitle: \"Hello Data World 1 (R)\"\ndate: 06/14/2022\nbibliography: r_references.bib\ncategories: [R]\neditor_options: \n  chunk_output_type: console\nformat:\n  html:\n    code-overflow: wrap  \nimage: Rlogo.png  \n---\n\n\n## Introduction\n\nIn programming it's traditional that the first thing you learn to do in a new language is to print 'Hello, World!' to the screen. This is the first of three 'Hello World' posts that will walk through some data handling & analysis tasks. These will be a bit more complex than printing 'Hello, World!' but will provide a look at how to approach data loading, exploration, filtering, plotting and statistical testing. Each post will use a different language & in this first post we will use [R](https://www.r-project.org/) - because it's the language I know best (i.e. least worst). The next two posts will carry out the same tasks using [python](https://www.python.org/) and [julia](https://julialang.org/). R and python are popular in data science and julia is a promising newcomer.\n\nIn each post we will load a dataset from a csv file, carry out some summarisation and exploratory plotting, some data filtering and finally carry out statistical testing on two groups using frequentist and Bayesian techniques. These are not exactly beginners posts but the aim is to give a flavour of how basic data exploration & analysis can be done in each language.\n\nIf you want to follow along the data are [here](https://github.com/iaingallagher/iaingallagher.github.io/tree/main/data).\n\n## Preliminaries\n\nR has a lot of base functionality for data handling, exploration & statistical analysis; it's what R was designed for. However we are going to make use of the 'tidyverse' [@wickham2019] because it has become a very popular approach to data handling & analysis in R.\n\n> The tidyverse encompasses the repeated tasks at the heart of every data science project: data import, tidying, manipulation, visualisation, and programming.\n\nAs well as data handling & visualisation we will also be carrying out some statistical testing. R is well served for basic frequentist statistics and there's nothing extra we need. For Bayesian analysis we will use the Stan probabilistic programming language [@carpenter2017]. We will code a model by hand and use the `cmdstanr` package to pass that model to Stan. We will also use the `brms` package [@bürkner2017] which makes writing Stan models easier. Details on how to install the `cmdstanr` package and Stan are [here](https://mc-stan.org/cmdstanr/) (see the section on *Installing CmdStan* for how to install `Stan`). Note that `brms` also needs `Stan` to be installed. We load the packages we need in the code below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# data loading & plotting\nlibrary(tidyverse) # meta-package; loads several packages\n# set theme for ggplot2 plotting\ntheme_set(theme_bw())\n# bayesian modeling\nlibrary(cmdstanr)\n# easier bayesian modeling\nlibrary(brms)\n# plot bayesian models\nlibrary(bayesplot)\n```\n:::\n\n\n### Loading the data\n\nThese data are from body composition practicals run as part of the Sport & Exercise Science degree at the University of Stirling. They were collected over a number of years by the students who carried out various measures on themselves.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load the data\ndata_in <- read_csv('data/BODY_COMPOSITION_DATA.csv')\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 203 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): sex\ndbl (9): girths, bia, DW, jackson, HW, skinfolds, BMI, WHR, Waist\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n:::\n\n\n### Exploration & tidying\n\nFirst we make sure the data looks as we expect it to.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# examine the data\nglimpse(data_in)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 203\nColumns: 10\n$ sex       <chr> \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", …\n$ girths    <dbl> 10.85, 14.12, 12.30, 8.50, 11.66, 15.65, 13.22, 14.62, 17.21…\n$ bia       <dbl> 5.7, 6.2, 6.3, 6.4, 6.6, 6.8, 6.9, 7.4, 7.6, 7.7, 7.8, 7.9, …\n$ DW        <dbl> 9.220, 11.800, 12.000, 10.850, 15.600, 21.420, 14.400, 9.820…\n$ jackson   <dbl> 4.75, 5.50, 5.50, 5.00, 12.00, 3.00, 7.80, 4.50, 9.00, 6.80,…\n$ HW        <dbl> 17.00, 16.90, 14.80, 10.20, 11.86, 33.10, 13.40, 14.35, 21.4…\n$ skinfolds <dbl> 50.75, 46.30, 45.80, 43.55, 93.50, 49.75, 56.70, 39.70, 73.5…\n$ BMI       <dbl> 20.70, 21.90, 21.39, 19.26, 22.30, 20.23, 23.54, 21.18, 20.5…\n$ WHR       <dbl> 0.8000, 0.8100, 0.7300, 0.7400, 0.7800, 0.8500, 0.8700, 0.77…\n$ Waist     <dbl> 76.5, 75.0, 70.0, 68.5, 74.0, 73.0, 80.0, 76.0, 75.0, 76.7, …\n```\n:::\n\n```{.r .cell-code}\nsummary(data_in) # tells us about NA values\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     sex                girths           bia              DW       \n Length:203         Min.   : 7.15   Min.   : 5.70   Min.   : 4.10  \n Class :character   1st Qu.:15.04   1st Qu.:11.90   1st Qu.:16.34  \n Mode  :character   Median :20.12   Median :16.20   Median :21.40  \n                    Mean   :20.70   Mean   :16.98   Mean   :21.66  \n                    3rd Qu.:24.60   3rd Qu.:21.18   3rd Qu.:28.00  \n                    Max.   :87.90   Max.   :39.30   Max.   :45.90  \n                                    NA's   :1                      \n    jackson            HW          skinfolds           BMI       \n Min.   : 3.00   Min.   : 4.10   Min.   : 27.75   Min.   : 2.90  \n 1st Qu.: 8.00   1st Qu.:15.04   1st Qu.: 59.27   1st Qu.:21.18  \n Median :12.80   Median :21.00   Median : 76.23   Median :23.00  \n Mean   :14.23   Mean   :21.42   Mean   : 82.88   Mean   :23.25  \n 3rd Qu.:19.00   3rd Qu.:27.00   3rd Qu.:100.67   3rd Qu.:24.80  \n Max.   :35.00   Max.   :43.00   Max.   :181.00   Max.   :33.03  \n                 NA's   :1                                       \n      WHR             Waist       \n Min.   :0.6700   Min.   : 61.00  \n 1st Qu.:0.7400   1st Qu.: 72.25  \n Median :0.7800   Median : 76.00  \n Mean   :0.7821   Mean   : 76.84  \n 3rd Qu.:0.8170   3rd Qu.: 81.00  \n Max.   :0.9900   Max.   :100.80  \n                                  \n```\n:::\n:::\n\n\nWe should deal with the missing values before we do any further analysis. There are many ways to deal with missing values but here we will just drop rows with missing values from the data using the `complete.cases()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# drop rows with NA values\ndata_in <- data_in[complete.cases(data_in), ]\nsummary(data_in)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     sex                girths           bia              DW       \n Length:201         Min.   : 7.15   Min.   : 5.70   Min.   : 4.10  \n Class :character   1st Qu.:15.08   1st Qu.:11.90   1st Qu.:16.30  \n Mode  :character   Median :20.12   Median :15.90   Median :21.40  \n                    Mean   :20.73   Mean   :16.98   Mean   :21.61  \n                    3rd Qu.:24.40   3rd Qu.:21.20   3rd Qu.:28.00  \n                    Max.   :87.90   Max.   :39.30   Max.   :45.90  \n    jackson            HW          skinfolds           BMI       \n Min.   : 3.00   Min.   : 4.10   Min.   : 27.75   Min.   : 2.90  \n 1st Qu.: 8.00   1st Qu.:15.00   1st Qu.: 59.25   1st Qu.:21.17  \n Median :12.60   Median :21.00   Median : 76.23   Median :23.00  \n Mean   :14.21   Mean   :21.43   Mean   : 82.68   Mean   :23.22  \n 3rd Qu.:19.00   3rd Qu.:27.00   3rd Qu.:100.35   3rd Qu.:24.80  \n Max.   :35.00   Max.   :43.00   Max.   :181.00   Max.   :33.03  \n      WHR             Waist       \n Min.   :0.6700   Min.   : 61.00  \n 1st Qu.:0.7400   1st Qu.: 72.00  \n Median :0.7800   Median : 76.00  \n Mean   :0.7815   Mean   : 76.76  \n 3rd Qu.:0.8150   3rd Qu.: 81.00  \n Max.   :0.9900   Max.   :100.80  \n```\n:::\n:::\n\n\nAccording to the 'tidy data' philosophy [@wickham2014] we want our data in long format rather than wide format. This also makes it easier to carry out later data wrangling, plotting and testing.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# wide to long data\ndata_inL <- pivot_longer(data_in, cols = `girths`:`Waist`, names_to = 'measure', values_to = 'value')\nhead(data_inL)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 3\n  sex   measure   value\n  <chr> <chr>     <dbl>\n1 M     girths    10.8 \n2 M     bia        5.7 \n3 M     DW         9.22\n4 M     jackson    4.75\n5 M     HW        17   \n6 M     skinfolds 50.8 \n```\n:::\n:::\n\n\nNow the values for each individual and each measurement technique are identified by rows rather than spread across row & column combinations. Exploration with plots is an essential step for checking values and the distribution of data. The `tidyverse` provides the `ggplot2` package for this.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# custom colors for male & female\nplot_cols <- c('firebrick', 'cornflowerblue')\n# make the plot\nggplot(data_inL, aes(sex, value, colour = sex)) + geom_jitter(width = 0.1) + \n  scale_colour_manual(values = plot_cols) + \n  theme(legend.position = \"none\") +\n  facet_wrap(~measure, scales = \"free_y\")\n```\n\n::: {.cell-output-display}\n![](hello_world_data_R_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nThere are a couple of mad values in the `BMI` and `girths` variables. For the rest of the analysis we'll concentrate on the `BMI` variable. Removing outliers is a contentious subject but here a BMI of 2 is incompatible with life! So we'll remove this unreasonably low value.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get just bmi data\nbmi_data <- data_inL %>% filter(measure == \"BMI\")\n# remove low value\nbmi_data <- bmi_data %>% filter(value > 15)\n# check with a new plot\nbmi_data %>% ggplot(aes(sex, value, colour = sex)) + geom_jitter(width = 0.1, size = 3) +\n  scale_colour_manual(values = plot_cols) + \n  theme(legend.position = \"none\") \n```\n\n::: {.cell-output-display}\n![](hello_world_data_R_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nMuch better! \n\n### Frequentist testing\n\nNow let's use a t-test to examine whether male and female BMI is different. In R basic statistical tests are easy; there are no extraneous packages to load and there's a pretty simple 'formula' interface using the tilde (`~`). Note that by default R uses Welch's t-test which does not assume equal variances in each group (see `?t.test`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# t-test\nt.test(value ~ sex, data = bmi_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  value by sex\nt = -2.1134, df = 192.05, p-value = 0.03586\nalternative hypothesis: true difference in means between group F and group M is not equal to 0\n95 percent confidence interval:\n -1.59338708 -0.05499779\nsample estimates:\nmean in group F mean in group M \n       22.83834        23.66253 \n```\n:::\n:::\n\n\nThe difference between male & female BMI is significant. This means that in a hypothetical long series of repeats of this study with different samples from the same population we would expect to see a difference as big or bigger between the sexes in more than 95% of those study repeats.\n\n### Bayesian testing\n\nThere are several packages for Bayesian statistics in R. We'll use the `cmdstanr` package to write a Bayesian model in the `Stan` probabilistic programming language for assessing the difference between male and female BMI. `Stan` will do the heavy lifting for us (Markov Chain Monte Carlo (MCMC sampling)) and return a data object we can use in R.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create data list\nsex <- bmi_data %>% select(sex) %>% pull() # labels for participant sex\n# convert to dummy coding; females are coded as 0\nsex_dummy <- ifelse(sex == 'F', 0, 1)\n# bmi values\nbmi <- bmi_data %>% select(value) %>% pull() \n# get num subjects\nN <- nrow(bmi_data) # length of dataset\n# make a list of data to pass to Stan\ndata_list <- list(N = N, sex = sex_dummy, bmi = bmi)\n\n# define the model in Stan as a text string; can also pass in a separate .stan file\n# stan code is written in blocks (data, parameters, model etc) defined by {}\nmodel_string <- \"\n\n// data we want to model\ndata{\n  int<lower=1> N; // length of the data\n  vector[N] bmi; // bmi data of length N\n  vector[N] sex; // sex data of length N\n}\n\n// parameters we want to estimate\nparameters{\n  real beta0; // intercept\n  real beta1; // slope\n  real<lower=0> sigma; // residual sd, must be positive\n}\n\n// priors for model\nmodel{\n  // priors\n  beta0 ~ normal(25, 10); // intercept\n  beta1 ~ normal(0, 5); // slope\n  sigma ~ normal(0,100); // defined as positive only in parameters block\n  \n  //likelihood\n  bmi ~ normal(beta0 + beta1*sex, sigma);\n}\"\n\n# write file to temp dir\nstan_mod_temp <- write_stan_file(model_string, dir = tempdir())\n# create Stan model\nstan_mod <- cmdstan_model(stan_mod_temp)\n# fit the model using Stan\nfit <- stan_mod$sample(data = data_list, seed = 123, chains = 4, parallel_chains = 2, refresh = 500 )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 chains, at most 2 in parallel...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.3 seconds.\n```\n:::\n\n```{.r .cell-code}\n# summary plus diagnostics\nfit$summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 10\n  variable     mean   median    sd   mad       q5     q95  rhat ess_bulk\n  <chr>       <num>    <num> <num> <num>    <num>   <num> <num>    <num>\n1 lp__     -306.    -306.    1.19  0.980 -308.    -305.    1.00    1899.\n2 beta0      22.8     22.8   0.313 0.322   22.3     23.4   1.00    2021.\n3 beta1       0.813    0.812 0.406 0.405    0.136    1.47  1.00    1965.\n4 sigma       2.82     2.82  0.140 0.140    2.60     3.07  1.00    2856.\n# ℹ 1 more variable: ess_tail <num>\n```\n:::\n\n```{.r .cell-code}\n# just the params\n# fit$summary(c(\"beta0\", \"beta1\", \"sigma\"), \"mean\", \"sd\")\n```\n:::\n\n\nThe output tells us that the estimated means for female BMI is 22.8 (females were dummy coded as 0). Given the priors we used we can say that there is a 90% probability that the value for female BMI lies between 22.3 and 23.4. The estimated male BMI is 0.81 (with 90% probability of being between 0.13 & 1.48) units greater than female BMI i.e. ~23.6. The mean values are the same as estimated by the frequentist $t$-test procedure. \n\nTo plot the posterior distributions we can extract the posterior draws and use the `bayesplot` package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get the draws; uses posterior package\ndraws <- fit$draws(variables = c('beta0', 'beta1', 'sigma'))\n# plot the draws; bayesplot package\nmcmc_dens(draws)\n```\n\n::: {.cell-output-display}\n![](hello_world_data_R_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nPlotting the posterior distribution for the male BMI is as simple as adding together the draws for `beta0` and `beta1`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# draws to dataframe\ndraws_df <- as_draws_df(draws)\n# posterior for male bmi included\nbmi_posteriors <- draws_df %>% mutate(male_bmi_post = beta0 + beta1)\nmcmc_dens(bmi_posteriors, pars = c('beta0', 'male_bmi_post', 'sigma'))\n```\n\n::: {.cell-output-display}\n![](hello_world_data_R_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nThere are easier ways to create basic (and more complex) Bayesian models than writing out the `Stan` code by hand. The `brms` package allows us to write Bayesian models using R modeling syntax. The model is translated to `Stan` and then compiled & run.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# brms bayesian modelling; same priors as above\nbrms_mod <- brm(value ~ sex, data = bmi_data,\n                prior = c(prior(normal(25, 10), class = \"Intercept\"), # prior on intercept\n                          prior(normal(0, 5), class = \"b\", coef = 'sexM'), # prior on slope\n                          prior(normal(0, 100), class = \"sigma\")), # prior on resid var\n                iter = 3000, warmup = 500, chains = 4, seed = 1234)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nCompiling Stan program...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nStart sampling\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL '38af6dc35b245825a290a54ed93cd989' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 7e-06 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 3000 [  0%]  (Warmup)\nChain 1: Iteration:  300 / 3000 [ 10%]  (Warmup)\nChain 1: Iteration:  501 / 3000 [ 16%]  (Sampling)\nChain 1: Iteration:  800 / 3000 [ 26%]  (Sampling)\nChain 1: Iteration: 1100 / 3000 [ 36%]  (Sampling)\nChain 1: Iteration: 1400 / 3000 [ 46%]  (Sampling)\nChain 1: Iteration: 1700 / 3000 [ 56%]  (Sampling)\nChain 1: Iteration: 2000 / 3000 [ 66%]  (Sampling)\nChain 1: Iteration: 2300 / 3000 [ 76%]  (Sampling)\nChain 1: Iteration: 2600 / 3000 [ 86%]  (Sampling)\nChain 1: Iteration: 2900 / 3000 [ 96%]  (Sampling)\nChain 1: Iteration: 3000 / 3000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.005785 seconds (Warm-up)\nChain 1:                0.020606 seconds (Sampling)\nChain 1:                0.026391 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL '38af6dc35b245825a290a54ed93cd989' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 3e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 3000 [  0%]  (Warmup)\nChain 2: Iteration:  300 / 3000 [ 10%]  (Warmup)\nChain 2: Iteration:  501 / 3000 [ 16%]  (Sampling)\nChain 2: Iteration:  800 / 3000 [ 26%]  (Sampling)\nChain 2: Iteration: 1100 / 3000 [ 36%]  (Sampling)\nChain 2: Iteration: 1400 / 3000 [ 46%]  (Sampling)\nChain 2: Iteration: 1700 / 3000 [ 56%]  (Sampling)\nChain 2: Iteration: 2000 / 3000 [ 66%]  (Sampling)\nChain 2: Iteration: 2300 / 3000 [ 76%]  (Sampling)\nChain 2: Iteration: 2600 / 3000 [ 86%]  (Sampling)\nChain 2: Iteration: 2900 / 3000 [ 96%]  (Sampling)\nChain 2: Iteration: 3000 / 3000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.005628 seconds (Warm-up)\nChain 2:                0.020249 seconds (Sampling)\nChain 2:                0.025877 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL '38af6dc35b245825a290a54ed93cd989' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 2e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 3000 [  0%]  (Warmup)\nChain 3: Iteration:  300 / 3000 [ 10%]  (Warmup)\nChain 3: Iteration:  501 / 3000 [ 16%]  (Sampling)\nChain 3: Iteration:  800 / 3000 [ 26%]  (Sampling)\nChain 3: Iteration: 1100 / 3000 [ 36%]  (Sampling)\nChain 3: Iteration: 1400 / 3000 [ 46%]  (Sampling)\nChain 3: Iteration: 1700 / 3000 [ 56%]  (Sampling)\nChain 3: Iteration: 2000 / 3000 [ 66%]  (Sampling)\nChain 3: Iteration: 2300 / 3000 [ 76%]  (Sampling)\nChain 3: Iteration: 2600 / 3000 [ 86%]  (Sampling)\nChain 3: Iteration: 2900 / 3000 [ 96%]  (Sampling)\nChain 3: Iteration: 3000 / 3000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.005748 seconds (Warm-up)\nChain 3:                0.018951 seconds (Sampling)\nChain 3:                0.024699 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL '38af6dc35b245825a290a54ed93cd989' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 2e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 3000 [  0%]  (Warmup)\nChain 4: Iteration:  300 / 3000 [ 10%]  (Warmup)\nChain 4: Iteration:  501 / 3000 [ 16%]  (Sampling)\nChain 4: Iteration:  800 / 3000 [ 26%]  (Sampling)\nChain 4: Iteration: 1100 / 3000 [ 36%]  (Sampling)\nChain 4: Iteration: 1400 / 3000 [ 46%]  (Sampling)\nChain 4: Iteration: 1700 / 3000 [ 56%]  (Sampling)\nChain 4: Iteration: 2000 / 3000 [ 66%]  (Sampling)\nChain 4: Iteration: 2300 / 3000 [ 76%]  (Sampling)\nChain 4: Iteration: 2600 / 3000 [ 86%]  (Sampling)\nChain 4: Iteration: 2900 / 3000 [ 96%]  (Sampling)\nChain 4: Iteration: 3000 / 3000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.005496 seconds (Warm-up)\nChain 4:                0.021491 seconds (Sampling)\nChain 4:                0.026987 seconds (Total)\nChain 4: \n```\n:::\n\n```{.r .cell-code}\n# model summary\nsummary(brms_mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: value ~ sex \n   Data: bmi_data (Number of observations: 200) \n  Draws: 4 chains, each with iter = 3000; warmup = 500; thin = 1;\n         total post-warmup draws = 10000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    22.84      0.31    22.22    23.46 1.00     9382     7692\nsexM          0.82      0.41     0.01     1.63 1.00    10240     7126\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     2.82      0.14     2.56     3.12 1.00     9313     7484\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n:::\n\n\nThe values for each coefficient are the same as both the frequentist model and the handcoded `Stan` model (as we'd expect).\n\nPlotting the model can be done with the `mcmc_plot()` function in `brms`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# plot the draws using built-in brms functions (that calls bayesplot)\n# regex  = TRUE for regular expression (^b) to pull out beta coefficients\nmcmc_plot(brms_mod, variable = c('^b', 'sigma'), type = 'dens', regex = TRUE)\n```\n\n::: {.cell-output-display}\n![](hello_world_data_R_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nAn even easier (but less flexible) package is [`rstanarm`](https://mc-stan.org/rstanarm/).\n\n## Summary\n\nThis post has been a quick skip through some data loading, exploration, filtering and both frequentist & Bayesian modelling in R.  ",
    "supporting": [
      "hello_world_data_R_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}