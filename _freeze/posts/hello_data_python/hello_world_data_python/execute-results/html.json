{
  "hash": "e3d13ede9cdc843773537ed2f0fe50c1",
  "result": {
    "markdown": "---\ntitle: Hello Data World 2 (python)\ndate: 08/03/2022\nbibliography: python_references.bib\ncategories:\n  - python\neditor_options:\n  chunk_output_type: console\nformat:\n  html:\n    code-overflow: wrap\nimage: python_logo.png\n---\n\n## Introduction\n\nThis is the second of three posts that will carry out data loading, exploration, filtering and statistical testing (frequentist & Bayesian). In the [first post](https://iaingallagher.github.io/posts/hello_data_r/hello_world_data_R.html) of the series we used [R](https://www.r-project.org). In this post we'll use [python](https://www.python.org). Like the previous post there won't be much exposition - we'll just move through the process. \n\nIf you want to follow along the data are [here](https://github.com/iaingallagher/iaingallagher.github.io/tree/main/data).\n\n### Preliminaries\n\nPython, like R, has a host of extra packages to help with data import, wrangling, plotting & building various kinds of models. The first step is to load the packages we will need. I use the [Anaconda python distribution](https://www.anaconda.com/products/distribution) and packages that are not installed by default can be installed with the [`conda`](https://conda.io/projects/conda/en/latest/user-guide/getting-started.html) tool. In this post we use the `pymc` package for Bayesian modeling. The [installation notes]() for `pymc` recommend installing it into its own python `conda` environment so this is what I did! To run the code in VSCode I set the relevant `python` interpreter by using Ctrl+Shift+P to bring up the Command Palette and selecting the relevant python environment. The other packages had to be installed into the same enviroment using `conda install`.\n\n![Setting the python environment](python_pymc_env_vscode.png){width=50%}\n\nOk, let's get on with loading the packages we'll need!\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd # dataframes for python\nimport plotnine as pn # ggplot2 clone\npn.options.figure_size = (5, 5) # set a default figure size for plotnine plots\npn.options.current_theme = pn.theme_bw() # set simple theme\nimport seaborn as sns # statistical plotting in python land\nsns.set_theme(style=\"whitegrid\") # plot theme\n# frequentist modeling\nimport scipy.stats as stats # classic freq stats for python\nimport pingouin as pg # alt to scipy.stats\n# bayesian modeling\nimport pymc as pm # write your models explicitly\nimport bambi as bmb # formula like interface\nimport arviz as az # plots for MCMC objects\n```\n:::\n\n\n### Loading the data\n\nWe can use the `read_csv()` function of the `pandas` [@rebackPandasdevPandasPandas2020] package to read in the data. These data are from body composition practicals run as part of the Sport & Exercise Science degree at the University of Stirling. They were collected over a numbers of years by the students who carried out various measures on themselves.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# get the data\ndata_in = pd.read_csv('data/BODY_COMPOSITION_DATA.csv', sep=',', na_values = \"NA\")\n```\n:::\n\n\n### Exploration & tidying\n\nThe `pandas` package also provides some tools for exploring the data. \n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ndata_in.head()\n# examine summary of types etc\ndata_in.info() # there are missing values in bia & HW\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 203 entries, 0 to 202\nData columns (total 10 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   sex        203 non-null    object \n 1   girths     203 non-null    float64\n 2   bia        202 non-null    float64\n 3   DW         203 non-null    float64\n 4   jackson    203 non-null    float64\n 5   HW         202 non-null    float64\n 6   skinfolds  203 non-null    float64\n 7   BMI        203 non-null    float64\n 8   WHR        203 non-null    float64\n 9   Waist      203 non-null    float64\ndtypes: float64(9), object(1)\nmemory usage: 16.0+ KB\n```\n:::\n:::\n\n\nWe can see that there are some missing values in the BIA and HW variables (these variables have 202 non-null values). There are many ways to deal with missing values but here we will just drop rows with missing values. The `dropna()` method for `pandas` dataframes allows us to drop rows (axis 0) or columns (axis 1) with missing values. We also specify the `inplace = True` argument so that the data we are working on is altered. \n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n# drop the rows (index 0) with missing values; alter dataframe (inplace = True)\ndata_in.dropna(axis = 0, inplace = True)\ndata_in.info() # all non-null values\n\n# summary stats\ndata_in.describe()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 201 entries, 0 to 201\nData columns (total 10 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   sex        201 non-null    object \n 1   girths     201 non-null    float64\n 2   bia        201 non-null    float64\n 3   DW         201 non-null    float64\n 4   jackson    201 non-null    float64\n 5   HW         201 non-null    float64\n 6   skinfolds  201 non-null    float64\n 7   BMI        201 non-null    float64\n 8   WHR        201 non-null    float64\n 9   Waist      201 non-null    float64\ndtypes: float64(9), object(1)\nmemory usage: 17.3+ KB\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>girths</th>\n      <th>bia</th>\n      <th>DW</th>\n      <th>jackson</th>\n      <th>HW</th>\n      <th>skinfolds</th>\n      <th>BMI</th>\n      <th>WHR</th>\n      <th>Waist</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>201.000000</td>\n      <td>201.000000</td>\n      <td>201.000000</td>\n      <td>201.000000</td>\n      <td>201.000000</td>\n      <td>201.000000</td>\n      <td>201.000000</td>\n      <td>201.000000</td>\n      <td>201.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>20.734552</td>\n      <td>16.980100</td>\n      <td>21.614647</td>\n      <td>14.212189</td>\n      <td>21.426408</td>\n      <td>82.684751</td>\n      <td>23.223000</td>\n      <td>0.781529</td>\n      <td>76.756716</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>8.382091</td>\n      <td>6.792665</td>\n      <td>7.307617</td>\n      <td>7.479344</td>\n      <td>8.006785</td>\n      <td>33.108192</td>\n      <td>3.168286</td>\n      <td>0.057142</td>\n      <td>7.352106</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>7.150000</td>\n      <td>5.700000</td>\n      <td>4.100000</td>\n      <td>3.000000</td>\n      <td>4.100000</td>\n      <td>27.750000</td>\n      <td>2.900000</td>\n      <td>0.670000</td>\n      <td>61.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>15.080000</td>\n      <td>11.900000</td>\n      <td>16.300000</td>\n      <td>8.000000</td>\n      <td>15.000000</td>\n      <td>59.250000</td>\n      <td>21.170000</td>\n      <td>0.740000</td>\n      <td>72.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>20.120000</td>\n      <td>15.900000</td>\n      <td>21.400000</td>\n      <td>12.600000</td>\n      <td>21.000000</td>\n      <td>76.230000</td>\n      <td>23.000000</td>\n      <td>0.780000</td>\n      <td>76.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>24.400000</td>\n      <td>21.200000</td>\n      <td>28.000000</td>\n      <td>19.000000</td>\n      <td>27.000000</td>\n      <td>100.350000</td>\n      <td>24.800000</td>\n      <td>0.815000</td>\n      <td>81.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>87.900000</td>\n      <td>39.300000</td>\n      <td>45.900000</td>\n      <td>35.000000</td>\n      <td>43.000000</td>\n      <td>181.000000</td>\n      <td>33.030000</td>\n      <td>0.990000</td>\n      <td>100.800000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nNext we will convert our data from wide format to long format [@wickham2014] with the  `pandas.melt()` function. Long data makes plotting and statistical analyses easier. In long format data the values for each individual and each measurement technique are identified by rows rather than spread across row & column combinations.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n# long data\ndataL = pd.melt(data_in, id_vars = \"sex\", var_name = \"method\", value_name = \"value\")\ndataL.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sex</th>\n      <th>method</th>\n      <th>value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M</td>\n      <td>girths</td>\n      <td>10.85</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M</td>\n      <td>girths</td>\n      <td>14.12</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M</td>\n      <td>girths</td>\n      <td>12.30</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M</td>\n      <td>girths</td>\n      <td>8.50</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M</td>\n      <td>girths</td>\n      <td>11.66</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nExploration with plots is an essential step for checking values and the distribution of data. There is an extensive plotting ecosystem in python. \n\n![Python visualisation landscape ([source](https://geo-python.github.io/site/lessons/L7/python-plotting.html))](python_viz_landscape.png)\n\nThe `seaborn` [@waskomSeabornStatisticalData2021] package provides a high level interface for plotting data & statistical summaries. If you're used to e.g. `ggplot2` in R then the [`plotnine`](https://plotnine.readthedocs.io/en/stable/) package provides very similar functionality.The tabs below demonstrate the same plot using each of these packages. \n\n::: {.panel-tabset}\n\n## seaborn\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nfg = sns.FacetGrid(dataL, col = 'method', hue = 'sex', col_wrap = 3, sharey = False); # create grid\n\nfg.map(sns.stripplot, 'sex', 'value', jitter = 0.05, size = 10, palette=[\"firebrick\", \"cornflowerblue\"], alpha = 0.5, order = [\"F\", \"M\"]); # map stripplot onto grid\n```\n\n::: {.cell-output .cell-output-display}\n![](hello_world_data_python_files/figure-html/cell-7-output-1.png){width=849 height=850}\n:::\n:::\n\n\n## plotnine\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\npt = pn.ggplot(dataL, pn.aes('sex', 'value', colour = 'sex')) + pn.geom_jitter(width = 0.1, alpha = 0.5) + pn.facet_wrap(\"method\", scales = \"free_y\") + pn.scale_colour_manual(values=['firebrick', 'cornflowerblue'])\npt\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/home/iain/anaconda3/envs/pymc_env/lib/python3.11/site-packages/plotnine/facets/facet.py:440: PlotnineWarning: If you need more space for the x-axis tick text use ... + theme(subplots_adjust={'wspace': 0.25}). Choose an appropriate value for 'wspace'.\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](hello_world_data_python_files/figure-html/cell-8-output-2.png){}\n:::\n:::\n\n\n:::\n\nThere are a couple of mad values in the `BMI` and `girths` variables. For the rest of the analysis we'll concentrate on the `BMI` variable. First we'll filter the data to just BMI.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\n# filter to just bmi data\nbmi_data = dataL[dataL.method == \"BMI\"]\nbmi_data.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 201 entries, 1206 to 1406\nData columns (total 3 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   sex     201 non-null    object \n 1   method  201 non-null    object \n 2   value   201 non-null    float64\ndtypes: float64(1), object(2)\nmemory usage: 6.3+ KB\n```\n:::\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\n# first few values\nbmi_data.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sex</th>\n      <th>method</th>\n      <th>value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1206</th>\n      <td>M</td>\n      <td>BMI</td>\n      <td>20.70</td>\n    </tr>\n    <tr>\n      <th>1207</th>\n      <td>M</td>\n      <td>BMI</td>\n      <td>21.90</td>\n    </tr>\n    <tr>\n      <th>1208</th>\n      <td>M</td>\n      <td>BMI</td>\n      <td>21.39</td>\n    </tr>\n    <tr>\n      <th>1209</th>\n      <td>M</td>\n      <td>BMI</td>\n      <td>19.26</td>\n    </tr>\n    <tr>\n      <th>1210</th>\n      <td>M</td>\n      <td>BMI</td>\n      <td>22.30</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWe'll re-plot these data.\n\n::: {.panel-tabset}\n## seaborn\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nbmi_pt1 = sns.stripplot(x = \"sex\", y = \"value\", data = bmi_data, jitter = 0.05, palette=[\"firebrick\", \"cornflowerblue\"], alpha = 0.8, order = [\"F\", \"M\"]);\nbmi_pt1\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\n<Axes: xlabel='sex', ylabel='value'>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](hello_world_data_python_files/figure-html/cell-11-output-2.png){width=592 height=437}\n:::\n:::\n\n\n## plotnine\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nbmi_pt2 = pn.ggplot(bmi_data, pn.aes(\"sex\", \"value\", colour = \"sex\")) + pn.geom_jitter(width = 0.1, alpha = 0.5) + pn.scale_colour_manual(values = [\"firebrick\", \"cornflowerblue\"])\nbmi_pt2\n```\n\n::: {.cell-output .cell-output-display}\n![](hello_world_data_python_files/figure-html/cell-12-output-1.png){}\n:::\n:::\n\n\n:::\n\nWe can clearly see the outlier in the male data. Removing outliers is a contentious subject but a BMI of 2 is unrealistic so we'll remove this value.\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\n# note very low bmi point in M; let's drop that\nbmi_data = bmi_data[bmi_data.value > 15]\n# summary\nbmi_data.describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>200.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>23.324615</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.828887</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>18.080000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>21.177500</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>23.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>24.802500</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>33.030000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.panel-tabset}\n## seaborn\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\n# seaborn plot\nbmi_pt3 = sns.stripplot(x = \"sex\", y = \"value\", data = bmi_data, jitter = 0.05, palette=[\"firebrick\", \"cornflowerblue\"], alpha = 0.8, order = [\"F\", \"M\"]);\nbmi_pt3\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\n<Axes: xlabel='sex', ylabel='value'>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](hello_world_data_python_files/figure-html/cell-14-output-2.png){width=592 height=437}\n:::\n:::\n\n\n## plotnine\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\n# plotnine plot\nbmi_pt4 = pn.ggplot(bmi_data, pn.aes(\"sex\", \"value\", colour = \"sex\")) + pn.geom_jitter(width = 0.1, alpha = 0.5) + pn.scale_colour_manual(values = [\"firebrick\", \"cornflowerblue\"])\nbmi_pt4\n```\n\n::: {.cell-output .cell-output-display}\n![](hello_world_data_python_files/figure-html/cell-15-output-1.png){}\n:::\n:::\n\n\n:::\n\nMuch better!\n\n## Frequentist testing\n\nWe're now in a position to undertake some statistical analysis. We'll start with a simple t-test to examine the mean difference in BMI between males and females. The `scipy.stats` [@virtanenSciPyFundamentalAlgorithms2020] library provides functions for one sample, paired & independent t-tests (and other tests). We first extract the data we want to test into separate series and then pass these series to the appropriate function. The `stats.ttest_ind()` function returns a tuple containing the t-statistic and the p-value for the test and we can extract these and print those. The `equal_var = False` argument means we get Welch's t-test which *doesn't* assume equal variances in each group.\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\n# test diff between men & women; get data\nmale_data = bmi_data[bmi_data.sex == \"M\"]\nfemale_data = bmi_data[bmi_data.sex == \"F\"]\n\n# do the test\nt_res = stats.ttest_ind(male_data.value, female_data.value, equal_var = False) # tuple out, t-stat and p-value\nt_res\n# print informative result\nprint(\"The t-statistic is %.2f with a p-value of %.3f.\" % (t_res[0], t_res[1]))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe t-statistic is 2.11 with a p-value of 0.036.\n```\n:::\n:::\n\n\nThe `pingouin` [@vallatPingouinStatisticsPython2018] package also provides functions for statistical testing.\n\nUsing the `ttest()` function with `correction = 'auto'` means `pingouin` automatically uses Welch's T-test when the sample sizes are unequal as they are here.\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\n# pingouin example; correction =‘auto’\npg.ttest(male_data.value, female_data.value, paired = False, correction = 'auto')\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>T</th>\n      <th>dof</th>\n      <th>alternative</th>\n      <th>p-val</th>\n      <th>CI95%</th>\n      <th>cohen-d</th>\n      <th>BF10</th>\n      <th>power</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>T-test</th>\n      <td>2.11342</td>\n      <td>192.047574</td>\n      <td>two-sided</td>\n      <td>0.035856</td>\n      <td>[0.05, 1.59]</td>\n      <td>0.293662</td>\n      <td>1.242</td>\n      <td>0.529014</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThe `pingouin` package provides us with much more information - which may or may not be useful to you. The difference between male & female BMI is significant. This means that in a hypothetical long series of repeats of this study with different samples from the same population we would expect to see a difference as big or bigger between the sexes in more than 95% of those repeats. The `pingouin` package also reports the power of the test here. This is post-hoc power though & post-hoc power is witchcraft e.g. [@gelmanDonCalculatePosthoc2019].\n\n## Bayesian testing\n\nIn the previous post with R we used the Stan probabilistic programming language to create a Bayesian model for the BMI data. We could also use Stan here via the [pystan](https://pystan.readthedocs.io/en/latest/index.html) interface but instead we'll use a native python library called [`pymc`] [@salvatierProbabilisticProgrammingPython2016]. The `pymc` package allows us to write data generating models and then use Markov Chain Monte Carlo (MCMC) sampling with those model definitions to generate posterior distributions. `pymc` supports a range of MCMC algorithms. In the code below we use the same priors we defined in the post using R.\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\n# bayesian test with pymc\n# create dummy variables; F = 0, M = 1\nbmi_data_dummy = pd.get_dummies(bmi_data, columns = [\"sex\"], drop_first = True)\n\n# set up priors & likelihood\n# https://docs.pymc.io/en/latest/api/generated/pymc.sample.html\nwith pm.Model() as model:  # model specifications in PyMC3 are wrapped in a `with` statement\n\n    # Define priors\n    sigma = pm.HalfNormal(\"sigma\", sigma = 100)\n    intercept = pm.Normal(\"Intercept\", mu = 25, sigma=10)\n    x_coeff = pm.Normal(\"male_diff\", mu = 0, sigma = 5)\n\n    # Define likelihood\n    likelihood = pm.Normal(\"value\", mu = intercept + x_coeff * bmi_data_dummy.sex_M, sigma=sigma, observed=bmi_data_dummy.value)\n```\n:::\n\n\nNext we run the MCMC sampling on the model we defined above; by default the NUTS algorithm is used. This is the same MCMC algorithm as the `Stan` probabilistic progamming language uses by default. Using `return_inferencedata = True` means we can easily plot the results (see below).\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\n# MCMC sampling\n# 3 MCMC chains\n# draw 3000 posterior samples using NUTS sampling; 1000 iter burn-in\nwith model:\n    bayes_bmi = pm.sample(3000, tune = 1000, return_inferencedata = True, chains = 3)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (3 chains in 4 jobs)\nNUTS: [sigma, Intercept, male_diff]\nSampling 3 chains for 1_000 tune and 3_000 draw iterations (3_000 + 9_000 draws total) took 2 seconds.\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n    <div>\n      <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.00% [12000/12000 00:01&lt;00:00 Sampling 3 chains, 0 divergences]\n    </div>\n    \n```\n:::\n:::\n\n\nThe `arviz` library [@kumarArviZUnifiedLibrary2019a] provides tools for summarising & plotting data from MCMC chains & posterior distributions.\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\naz.plot_trace(bayes_bmi);\n```\n\n::: {.cell-output .cell-output-display}\n![](hello_world_data_python_files/figure-html/cell-20-output-1.png){width=912 height=507}\n:::\n:::\n\n\nWe want the traceplots (on the right) to look like 'hairy caterpillars' & they all look fine here. The posterior distributions for each parameter also look healthy. We can plot the posteriors using `arviz` as well.\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\naz.plot_posterior(bayes_bmi, grid = (2,2), hdi_prob = 0.95);\n```\n\n::: {.cell-output .cell-output-display}\n![](hello_world_data_python_files/figure-html/cell-21-output-1.png){width=1217 height=912}\n:::\n:::\n\n\nThe posterior distributions all look good. We can extract the intercept posterior and the posterior for the effect of 'male' and add these together to get the posterior for male BMI.\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\n# add Intercept & male diff posteriors; keep this new posterior in existing InferenceData object\nbayes_bmi.posterior[\"male_bmi\"] = bayes_bmi.posterior[\"Intercept\"] + bayes_bmi.posterior[\"male_diff\"]\n\n# replot with only intercept (female BMI), male BMI and sigma\naz.plot_posterior(bayes_bmi, var_names = [\"Intercept\", \"male_bmi\", \"sigma\"]  , grid = (2,2), hdi_prob = 0.95);\n```\n\n::: {.cell-output .cell-output-display}\n![](hello_world_data_python_files/figure-html/cell-22-output-1.png){width=1217 height=912}\n:::\n:::\n\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\n# summary\naz.summary(bayes_bmi, var_names = [\"Intercept\", \"male_bmi\", \"sigma\"] , kind = \"stats\", hdi_prob = 0.9)\n```\n\n::: {.cell-output .cell-output-display execution_count=22}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>sd</th>\n      <th>hdi_5%</th>\n      <th>hdi_95%</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Intercept</th>\n      <td>22.835</td>\n      <td>0.316</td>\n      <td>22.292</td>\n      <td>23.317</td>\n    </tr>\n    <tr>\n      <th>male_bmi</th>\n      <td>23.661</td>\n      <td>0.258</td>\n      <td>23.247</td>\n      <td>24.099</td>\n    </tr>\n    <tr>\n      <th>sigma</th>\n      <td>2.826</td>\n      <td>0.143</td>\n      <td>2.588</td>\n      <td>3.051</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThe output tells us that the estimated mean for female BMI is 22.8 (females were dummy coded as 0). Given the priors we used we can say that there is a 90% probability that the value for female BMI lies between 22.3 and 23.4. The estimated male BMI is 23.6 with 90% probability of being between 23.2 & 24. Note that the actual values might vary in the decimal point because the MCMC chains are random.\n\nThe `bambi` library [@caprettoBambiSimpleInterface2022] can be used to create Bayesian models with a more intuitive formula interface like `brms` or `rstanarm` in R.\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\n# model with bambi\n# define priors\nprior_spec = {\n    \"Intercept\": bmb.Prior(\"Normal\", mu = 25, sigma = 10),\n    \"sex_M\": bmb.Prior(\"Normal\", mu = 0, sigma = 5),\n    \"value_sigma\": bmb.Prior(\"HalfNormal\", sigma = 100)\n}\n\n# define the model; formula syntax\nbmb_bayes_model = bmb.Model(\"value ~ sex\", priors = prior_spec, data = bmi_data)\n# MCMC sampling; returns InferenceData obj\nbmb_bayes_bmi = bmb_bayes_model.fit(draws = 3000, tune = 1000, chains = 3)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (3 chains in 4 jobs)\nNUTS: [value_sigma, Intercept, sex]\nSampling 3 chains for 1_000 tune and 3_000 draw iterations (3_000 + 9_000 draws total) took 2 seconds.\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n    <div>\n      <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.00% [12000/12000 00:01&lt;00:00 Sampling 3 chains, 0 divergences]\n    </div>\n    \n```\n:::\n:::\n\n\nThe `bmb_bayes_bmi` object is of type `InferenceData` like that returned from `pymc` (`bambi` uses `pymc` under the hood). We can use the `bambi` result in the same way we used the `pymc` result with `arviz`.\n\nFirst we'll plot the posterior distributions and plots for each MCMC chain.\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\n# plots and dists\naz.plot_trace(bmb_bayes_bmi);\n```\n\n::: {.cell-output .cell-output-display}\n![](hello_world_data_python_files/figure-html/cell-25-output-1.png){width=912 height=507}\n:::\n:::\n\n\nNext we'll plot the posterior distributions and get summaries of those posteriors.\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\n# plot posteriors\naz.plot_posterior(bmb_bayes_bmi, grid = (2,2), hdi_prob = 0.95);\n\n# Key summary and diagnostic info on the model parameters\naz.summary(bmb_bayes_bmi)\n```\n\n::: {.cell-output .cell-output-display execution_count=25}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>sd</th>\n      <th>hdi_3%</th>\n      <th>hdi_97%</th>\n      <th>mcse_mean</th>\n      <th>mcse_sd</th>\n      <th>ess_bulk</th>\n      <th>ess_tail</th>\n      <th>r_hat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Intercept</th>\n      <td>22.840</td>\n      <td>0.309</td>\n      <td>22.255</td>\n      <td>23.417</td>\n      <td>0.003</td>\n      <td>0.002</td>\n      <td>15248.0</td>\n      <td>7273.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>sex[M]</th>\n      <td>0.828</td>\n      <td>0.406</td>\n      <td>0.027</td>\n      <td>1.549</td>\n      <td>0.003</td>\n      <td>0.003</td>\n      <td>15087.0</td>\n      <td>7029.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>value_sigma</th>\n      <td>2.816</td>\n      <td>0.144</td>\n      <td>2.545</td>\n      <td>3.086</td>\n      <td>0.001</td>\n      <td>0.001</td>\n      <td>12954.0</td>\n      <td>6515.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](hello_world_data_python_files/figure-html/cell-26-output-2.png){width=1217 height=928}\n:::\n:::\n\n\nWe get some extra information using the `bambi` summary.\n\nAs we did in the `pymc3` example we can add the `Intercept` and `sex` chains together to get a posterior distribution for the male BMI and add this data to our existing `` object.\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\nbmb_bayes_bmi.posterior[\"male_bmi\"] = bmb_bayes_bmi.posterior[\"Intercept\"] + bmb_bayes_bmi.posterior[\"sex\"]\n```\n:::\n\n\nWe can easily summarise & plot the parameters we are interested in.\n\n::: {.cell execution_count=27}\n``` {.python .cell-code}\n# plot selected posteriors\naz.plot_posterior(bmb_bayes_bmi, var_names = [\"Intercept\", \"male_bmi\", \"value_sigma\"], grid = (2,2), hdi_prob = 0.95);\n\n# posterior summary\naz.summary(bmb_bayes_bmi, var_names = [\"Intercept\", \"male_bmi\", \"value_sigma\"], kind = \"stats\", hdi_prob = 0.9)\n```\n\n::: {.cell-output .cell-output-display execution_count=27}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>sd</th>\n      <th>hdi_5%</th>\n      <th>hdi_95%</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Intercept</th>\n      <td>22.840</td>\n      <td>0.309</td>\n      <td>22.322</td>\n      <td>23.335</td>\n    </tr>\n    <tr>\n      <th>male_bmi[M]</th>\n      <td>23.668</td>\n      <td>0.259</td>\n      <td>23.249</td>\n      <td>24.091</td>\n    </tr>\n    <tr>\n      <th>value_sigma</th>\n      <td>2.816</td>\n      <td>0.144</td>\n      <td>2.570</td>\n      <td>3.043</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](hello_world_data_python_files/figure-html/cell-28-output-2.png){width=1227 height=928}\n:::\n:::\n\n\n## Summary\n\nThis post has been a quick skip through some data loading, exploration, filtering and both frequentist & Bayesian modelling with python.  \n\n",
    "supporting": [
      "hello_world_data_python_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}